{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMl9tVCgJ2O7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "002662b9"
      },
      "source": [
        "## Python Generators\n",
        "\n",
        "A generator is a special type of function that returns an iterator. Unlike regular functions that return a single value and terminate, generators \"yield\" a sequence of values. This means they don't build the entire sequence in memory at once, making them very memory-efficient, especially for large datasets.\n",
        "\n",
        "Here's a simple example of a generator function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "443354a6",
        "outputId": "af74ac01-54fc-417b-e4e7-8d841c29bdb9"
      },
      "source": [
        "def simple_generator():\n",
        "    print(\"Starting to generate...\")\n",
        "    yield 1\n",
        "    print(\"Generated 1\")\n",
        "    yield 2\n",
        "    print(\"Generated 2\")\n",
        "    yield 3\n",
        "    print(\"Generated 3\")\n",
        "\n",
        "# Calling the generator function returns a generator object\n",
        "gen = simple_generator()\n",
        "\n",
        "# We can iterate through the generator\n",
        "print(\"First value:\", next(gen))\n",
        "print(\"Second value:\", next(gen))\n",
        "print(\"Third value:\", next(gen))\n",
        "\n",
        "try:\n",
        "    next(gen)\n",
        "except StopIteration:\n",
        "    print(\"Generator is exhausted\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to generate...\n",
            "First value: 1\n",
            "Generated 1\n",
            "Second value: 2\n",
            "Generated 2\n",
            "Third value: 3\n",
            "Generated 3\n",
            "Generator is exhausted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ed6654f"
      },
      "source": [
        "In the example above, the `simple_generator` function yields values one by one using the `yield` keyword. Each time `next()` is called on the generator object (`gen`), the function resumes execution from where it last yielded.\n",
        "\n",
        "This is particularly useful in data science and AI when dealing with large files or streams of data where loading everything into memory simultaneously is not feasible.\n",
        "\n",
        "Let's look at a more practical example related to data processing: reading large files line by line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db1db663",
        "outputId": "dbc33437-bce2-4043-d9b5-614b7bb770d9"
      },
      "source": [
        "# Create a dummy large file for demonstration\n",
        "with open(\"large_data.txt\", \"w\") as f:\n",
        "    for i in range(10000):\n",
        "        f.write(f\"Data line {i}\\n\")\n",
        "\n",
        "def read_large_file(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            yield line\n",
        "\n",
        "# Using the generator to process the file line by line\n",
        "print(\"\\nReading large_data.txt line by line:\")\n",
        "file_generator = read_large_file(\"large_data.txt\")\n",
        "\n",
        "# Process the first few lines\n",
        "for i in range(5):\n",
        "    print(next(file_generator).strip())\n",
        "\n",
        "# Clean up the dummy file\n",
        "import os\n",
        "os.remove(\"large_data.txt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading large_data.txt line by line:\n",
            "Data line 0\n",
            "Data line 1\n",
            "Data line 2\n",
            "Data line 3\n",
            "Data line 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aefde33f"
      },
      "source": [
        "## Python Generator Expressions\n",
        "\n",
        "Generator expressions are a concise way to create anonymous generator objects, similar to list comprehensions but using parentheses instead of square brackets. They are more memory-efficient than list comprehensions when you don't need the entire sequence in memory.\n",
        "\n",
        "Here's the syntax:\n",
        "\n",
        "`(expression for item in iterable if condition)`\n",
        "\n",
        "Let's see an example using data similar to what you might find in a data science context (e.g., processing numerical data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a99c46d",
        "outputId": "d8403e4b-08bb-49de-f385-0907ea06d29e"
      },
      "source": [
        "data_points = [10, 15, 22, 30, 5, 40, 8]\n",
        "\n",
        "# Using a list comprehension to get squares (loads all into memory)\n",
        "list_of_squares = [x**2 for x in data_points if x > 10]\n",
        "print(\"List comprehension result:\", list_of_squares)\n",
        "\n",
        "# Using a generator expression to get squares (yields one by one)\n",
        "generator_of_squares = (x**2 for x in data_points if x > 10)\n",
        "print(\"Generator expression object:\", generator_of_squares)\n",
        "\n",
        "# Iterate through the generator expression\n",
        "print(\"Iterating through generator expression:\")\n",
        "for square in generator_of_squares:\n",
        "    print(square)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List comprehension result: [225, 484, 900, 1600]\n",
            "Generator expression object: <generator object <genexpr> at 0x7a12652d3ed0>\n",
            "Iterating through generator expression:\n",
            "225\n",
            "484\n",
            "900\n",
            "1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d7581ea"
      },
      "source": [
        "Generator expressions are very useful for creating iterators on the fly, especially within function calls that consume iterators (like `sum()`, `max()`, `min()`, `any()`, `all()`, etc.).\n",
        "\n",
        "For example, calculating the sum of squares for data points greater than 10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61b6abf2",
        "outputId": "aa0b5a21-6a41-42fd-8cf8-64e5f850df6e"
      },
      "source": [
        "data_points = [10, 15, 22, 30, 5, 40, 8]\n",
        "\n",
        "# Using a generator expression directly in sum()\n",
        "sum_of_squares = sum(x**2 for x in data_points if x > 10)\n",
        "print(\"Sum of squares using generator expression:\", sum_of_squares)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of squares using generator expression: 3209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b8b7afe"
      },
      "source": [
        "### When to use Generators and Generator Expressions in Data Science/AI:\n",
        "\n",
        "*   **Processing large datasets:** Reading large CSV files, processing image pixel data, or handling large log files without loading everything into memory.\n",
        "*   **Streaming data:** Working with data streams from sensors, network connections, or real-time APIs.\n",
        "*   **Creating custom iterators:** When you need a specific sequence of values for training models or performing calculations.\n",
        "*   **Improving performance:** Reducing memory usage can prevent crashes and improve the overall performance of your data processing pipelines.\n",
        "\n",
        "Let me know if you would like to see more advanced examples or have any specific questions!"
      ]
    }
  ]
}